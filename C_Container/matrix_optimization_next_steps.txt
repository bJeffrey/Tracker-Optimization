Data residency model
- Warm store (disk, SQLite R*Tree + track table): authoritative state, covariance, metadata for all tracks.
- Hot store (RAM): only tracks in/near current scan volume (plus look-ahead buffer). Holds full state + covariance + metadata for the active working set.
- Hot index (RAM): spatial index for hot tracks only (fast query for gating/association).
- Warm index (disk): spatial index for all tracks (authoritative, used to populate hot).

Stage 0: Startup / Pre-run
- Warm: full dataset, persistent.
- Hot: empty (or restored from last snapshot if configured).
- Action: no batch compute yet.

Stage 1: Scan prefetch (before measurements)
- Warm: query R*Tree for scan AABB -> candidate IDs.
- Hot: load those IDs' state + covariance + metadata into hot.
- Batch use: build hot TrackBatch and TrackKinematicsBatch for all active IDs in one contiguous allocation.
Status: PARTIAL (IDs prefetched; full state/cov hydration not implemented)

Stage 2: Predict / propagate to scan time
- Hot: update state + covariance for hot tracks only.
- Batch use: run vectorized/batched propagation and rw_add_qdt_subset_var_dt on the hot subset (one kernel over contiguous hot arrays).
- Warm: unchanged (authoritative but stale until finalize).

Stage 3: Measurement generation (placeholder)
- Hot: no change to track storage.
- Warm: no change.

Stage 4: Coarse gating (hot only)
- Hot: run coarse gating against hot index + measurements.
- Batch use: vectorized distance/volume checks over hot subset.

Stage 5: Fine gating / association
- Hot: compute associations for hot tracks.
- Batch use: matrix ops over association candidates (compact arrays).

Stage 6: Filter update
- Hot: update state + covariance for associated tracks.
- Batch use: Kalman/filter updates in batches for associated tracks only.

Stage 7: Track maintenance / metadata
- Hot: update metadata (age, status, quality, last_update).
- Warm: still unchanged.

Stage 8: Finalize scan (persist to warm)
- Warm: update only tracks that changed (state + covariance + metadata).
- Hot: remains as working set until next scan.
- Optimization: write back only changed IDs, in a single transaction per scan. Avoid bulk re-writes.
Status: PARTIAL (index writeback only; state/cov/metadata persistence not implemented)

Key performance optimizations
- Hot contains only working set: RAM scales with scan density, not total tracks.
- Batch ops only on hot subset: leverage contiguous arrays for propagation and filter updates.
- Warm updates only for changed tracks: eliminates large disk writes per scan.
- Index update thresholds: hot index uses tighter thresholds; warm index uses looser thresholds to reduce disk churn.
- Prefetch window: optionally expand AABB by a look-ahead buffer so hot has tracks needed for the next scan, reducing warm query frequency.

Worker thread plan (additions)
- Prefetch worker: load next-scan AABB IDs and hydrate hot state/cov/metadata ahead of measurement time.
- Finalize worker: async warm flush after scan; write index + state/cov/metadata in a single transaction.
- Triggers: scan count, buffered track count, and shutdown (configurable thresholds in store.xml).
- Telemetry: prefetch latency, flush latency, queue depth, cache hit rate, commit timing captured in performance.csv.

Per-scan runtime candidates to move off the scan thread
- Measurement generation: truth â†’ AER/ENU conversions + noise (produce next scan's measurements in a worker).
- Association: candidate pairs scoring (thread-pool by measurement or by gate).
- Covariance aging: move to lower-rate background job or stagger across scans.
- Candidate pairs build: keep gate queries async and build pairs in worker too.
